// app/api/chat/route.ts
import type { NextRequest } from 'next/server'

const MOCK_RESPONSES = [
  {
    thinking: 'è®©æˆ‘åˆ†æžä¸€ä¸‹æ‚¨çš„å‡ºç”Ÿæ—¥æœŸ...\n\næ ¹æ®å…«å­—ç†è®ºï¼Œæˆ‘éœ€è¦å°†å…¬åŽ†æ—¥æœŸè½¬æ¢ä¸ºå†œåŽ†ï¼Œç„¶åŽè®¡ç®—å¤©å¹²åœ°æ”¯...',
    text: 'æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œæˆ‘æ¥ä¸ºæ‚¨åˆ†æžå…«å­—ï¼š\n\n**æ‚¨çš„å…«å­—æŽ’ç›˜**\n- å¹´æŸ±ï¼šç”²å­\n- æœˆæŸ±ï¼šä¸™å¯…\n- æ—¥æŸ±ï¼šæˆŠè¾°\n- æ—¶æŸ±ï¼šå£¬åˆ\n\n**äº”è¡Œåˆ†æž**\næ‚¨çš„å…«å­—ä¸­æœ¨ã€ç«è¾ƒæ—ºï¼ŒåœŸä¸ºæ—¥ä¸»ï¼Œæ•´ä½“æ ¼å±€åå‘ã€Œé£Ÿç¥žç”Ÿè´¢ã€ã€‚\n\næ‚¨å¸Œæœ›æˆ‘ä¸ºæ‚¨ç”Ÿæˆä¸€ä¸ªä»€ä¹ˆæ ·çš„å‰ç¥¥ç‰©å‘¢ï¼Ÿå¯ä»¥å‘Šè¯‰æˆ‘æ‚¨çš„åå¥½ï¼Œæ¯”å¦‚ï¼š\n- åŠ¨ç‰©ç±»ï¼ˆé¾™ã€å‡¤ã€éº’éºŸç­‰ï¼‰\n- æ¤ç‰©ç±»ï¼ˆèŽ²èŠ±ã€ç«¹å­ç­‰ï¼‰\n- æŠ½è±¡ç±»ï¼ˆç¥¥äº‘ã€å¦‚æ„ç­‰ï¼‰',
  },
  {
    thinking: 'ç”¨æˆ·æƒ³è¦ä¸€ä¸ªé¾™å½¢å‰ç¥¥ç‰©ï¼Œç»“åˆä»–çš„å…«å­—ç‰¹ç‚¹ï¼Œæˆ‘æ¥è®¾è®¡ä¸€ä¸ªé€‚åˆçš„é€ åž‹...',
    text: 'å¥½çš„ï¼åŸºäºŽæ‚¨çš„å…«å­—ç‰¹ç‚¹ï¼Œæˆ‘ä¸ºæ‚¨è®¾è®¡äº†ä¸€ä¸ª**ç¥¥é¾™çŒ®ç‘ž**å‰ç¥¥ç‰©ï¼š\n\nðŸ‰ **è®¾è®¡ç†å¿µ**\n- é¾™èº«çŽ¯ç»•ç¥¥äº‘ï¼Œè±¡å¾è…¾é£ž\n- é¾™çˆªæ¡å®ç ï¼Œå¯“æ„è´¢è¿äº¨é€š\n- åº•åº§ä¸ºèŽ²èŠ±ï¼Œå–ã€Œå’Œè°ã€ä¹‹æ„\n\næ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆ 3D æ¨¡åž‹ï¼Œè¯·ç¨å€™...',
    toolCall: {
      name: 'generate_3d_model',
      status: 'calling',
    },
  },
  {
    text: 'âœ¨ **3D æ¨¡åž‹ç”Ÿæˆå®Œæˆï¼**\n\næ‚¨çš„ä¸“å±žå‰ç¥¥ç‰©å·²ç»å‡†å¤‡å¥½äº†ï¼Œå¯ä»¥åœ¨å³ä¾§æŸ¥çœ‹å’Œæ—‹è½¬æ¨¡åž‹ã€‚\n\nå¦‚æžœæ»¡æ„ï¼Œå¯ä»¥ç‚¹å‡»ã€Œä¸‹å•æ‰“å°ã€å°†å®ƒå˜æˆå®žç‰©ï¼',
    toolCall: {
      name: 'generate_3d_model',
      status: 'complete',
      result: 'https://example.com/model.glb',
    },
    modelReady: true,
  },
]

export async function POST(req: NextRequest) {
  const { messages } = await req.json()

  // æ ¹æ®ç”¨æˆ·æ¶ˆæ¯æ•°é‡é€‰æ‹©å“åº”ï¼ˆæ¯2æ¡æ¶ˆæ¯=1è½®å¯¹è¯ï¼‰
  const userMessageCount = messages.filter((m: { role: string }) => m.role === 'user').length
  const responseIdx = Math.min(userMessageCount - 1, MOCK_RESPONSES.length - 1)
  const mockResponse = MOCK_RESPONSES[Math.max(0, responseIdx)]

  // åˆ›å»ºæµå¼å“åº”
  const encoder = new TextEncoder()
  const stream = new ReadableStream({
    async start(controller) {
      // å‘é€æ€è€ƒè¿‡ç¨‹
      if (mockResponse.thinking) {
        controller.enqueue(encoder.encode(`data: ${JSON.stringify({
          type: 'reasoning',
          content: mockResponse.thinking,
        })}\n\n`))
        await delay(500)
      }

      // å‘é€å·¥å…·è°ƒç”¨çŠ¶æ€
      if (mockResponse.toolCall?.status === 'calling') {
        controller.enqueue(encoder.encode(`data: ${JSON.stringify({
          type: 'tool-call',
          name: mockResponse.toolCall.name,
          status: 'calling',
        })}\n\n`))
        await delay(300)
      }

      // æµå¼å‘é€æ–‡æœ¬
      const chars = mockResponse.text.split('')
      for (const char of chars) {
        controller.enqueue(encoder.encode(`data: ${JSON.stringify({
          type: 'text-delta',
          content: char,
        })}\n\n`))
        await delay(20)
      }

      // å‘é€å·¥å…·è°ƒç”¨å®Œæˆ
      if (mockResponse.toolCall?.status === 'complete') {
        controller.enqueue(encoder.encode(`data: ${JSON.stringify({
          type: 'tool-call',
          name: mockResponse.toolCall.name,
          status: 'complete',
          result: mockResponse.toolCall.result,
        })}\n\n`))
      }

      // å‘é€æ¨¡åž‹å°±ç»ªä¿¡å·
      if (mockResponse.modelReady) {
        controller.enqueue(encoder.encode(`data: ${JSON.stringify({
          type: 'model-ready',
          url: 'https://modelviewer.dev/shared-assets/models/Astronaut.glb',
        })}\n\n`))
      }

      controller.enqueue(encoder.encode('data: [DONE]\n\n'))
      controller.close()
    },
  })

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  })
}

function delay(ms: number) {
  return new Promise(resolve => setTimeout(resolve, ms))
}
